---
title: Building and estimating a first Bayesian model
author: Marie-Pierre Etienne, Etienne Rivot 
institute: "https://marieetienne.github.io/bayesian_and_ecology"
date: "M2 Mode - Data science"
csl: "../resources/apa-no-doi-no-issue.csl"
output:
   xaringan::moon_reader:
    css: ['metropolis',  'mpe_pres.css']
    lib_dir: libs
    nature:
      ratio: 16:10
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: '../courses_tools/resources/collapseoutput.js'
---


```{r datapackage, eval = TRUE, echo = FALSE, warning = FALSE}
ggplot <- function(...) ggplot2::ggplot(...) + scale_fill_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) + scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) 
#remotes::install_github('MarieEtienne/coursesdata', force = TRUE)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rjags)
library(ggmcmc)


mypal <- wesanderson::wes_palette("Darjeeling1")
theme_set(theme_light())
```

---
name: coin 
# Tossing a coin
--

While tossing a coin 53 times, we got 9 tails. What could we say on the probability to get a tail ?
## Model of experiment

We model the experiment by 
$$ Y \sim \mathcal{B}(m, p),$$ 
with $p$ the probability to get a tail and $m$ the total number of trials. 

---
template: coin
## Modelling the prior knowledge on $p$

As we never used that coin, we would like to add no information in the prior information. FIrst guess

$$ p \sim \mathcal{U}(0,1)$$

which is equivalent to

$$ p \sim \mathcal{B}eta(1,1)$$
---
template: coin
## Theoretical posterior distribution

The full bayesian specification for the model is a so called beta binomial model which has analytical posterior distribution.

$$\pi(p\vert  Y_{obs}) \sim \mathcal{B}eta(Y_{obs} + 1,  m-Y_{obs} +1)$$
---
template: coin
## Theoretical posterior distribution

Graphically

```{r first_data}
Y <- 9
m <- 53
```

```{r echo = FALSE}
s1 <- 1
s2 <- 1
dta <- data.frame(x=seq(0,1, length.out = 100))
p <- ggplot(data = dta)
stat_post <- stat_function(data = dta, aes(x = x, y = ..y..), fun = dbeta, colour=mypal[1], n = 100,
                      args = list(shape1 = Y+s1, shape2 = m-Y+s2))
stat_prior <- stat_function(data = dta, aes(x = x, y = ..y..), fun = dbeta, colour=mypal[2], n = 100,
                      args = list(shape1 = s1, shape2 = s2))
p + stat_prior +stat_post 

```

---
name: sampling
# Sampling from the posterior distribution

--
## Practical Model specification


```{r model_specification, echo = TRUE}
model <- "
model{

  ## model 
  Y ~ dbinom(p, m)

  ## Prior distribution
  p ~ dbeta(1, 1)

} # end model
"

```



---
template: sampling
## Data specification 

```{r data}
data_list <- list(
  m = 53,
  Y = 9
)
```


---
template: sampling
## Initialisation 


```{r init}
init_list <- list(
  p=0.1
)
```




---
template: sampling
## Combining, model and data


```{r jags_model}
mjags <- jags.model(file=textConnection(model), 
                    data=data_list,
                    inits=init_list, 
                    n.chains = 3)

```



---
template: sampling
## Sampling from the posterior

We are interested in the posteriori distribution of $p$


```{r postsamples}
postSamples <- coda.samples(mjags, 
                            variable.names = c("p"),
                            n.iter = 50000, 
                            thin = 100)

```


---
template: sampling
## Comparing sampled and theoretical distributions


```{r post_sample, echo = FALSE, eval = FALSE}
## a nicer format 
postSamples_df <-  postSamples %>% ggs()

postSamples_df %>%
  ggplot() + 
  facet_wrap(~as.factor(Chain)) +
  geom_histogram(data = postSamples_df, aes(x= value, y =..density.., fill = as.factor(Chain)), position = "identity", alpha = 0.7) + scale_fill_manual(values = wesanderson::wes_palette("FantasticFox1", n = 5)) + 
  stat_prior +
  stat_post   
```




---

`r chunk_reveal("post_sample", break_type = "auto")`


---
name: CMR
# Capture Mak Recapture

While monitoring a large population of size $n$ unknown, $m$ individuals have been marked and released.
The population might be considered as $m$ marked individuals and $n-m$ unmarked individuals. 
A recapture experiment leads to $YM$ marked animals and $YNM$ unmarked. 

m = 53, YM = 9 and YNM = 75 ?



What is the size of the population ?
Under what assumptions ?

---
template: CMR
## Estimating the capture efficiency

The probability of capture might be infered from the recapture dataset and the experiment might be modelled as 
\begin{equation}
 YM \sim \mathcal{B}(m, p).
\end{equation}

The capture mark recapture experiment has been used for the first time on these conditions. Few is known on the probability of capture. Therefore an uniform prior is chosen to model the a priori knowledge on $p$.


---
template: CMR
## Data
```{r}
m <- 53
YM <- 9
```




---
template: CMR
## Let's figure out the rest of the model
